{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/quora-insincere-questions-classification/train.csv\n/kaggle/input/quora-insincere-questions-classification/sample_submission.csv\n/kaggle/input/quora-insincere-questions-classification/test.csv\n/kaggle/input/quora-insincere-questions-classification/embeddings/paragram_300_sl999/paragram_300_sl999.txt\n/kaggle/input/quora-insincere-questions-classification/embeddings/paragram_300_sl999/README.txt\n/kaggle/input/quora-insincere-questions-classification/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec\n/kaggle/input/quora-insincere-questions-classification/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\n/kaggle/input/quora-insincere-questions-classification/embeddings/glove.840B.300d/glove.840B.300d.txt\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\ntqdm.pandas()","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/quora-insincere-questions-classification/train.csv\")\ntest = pd.read_csv(\"../input/quora-insincere-questions-classification/test.csv\")\nprint(\"Train shape : \",train.shape)\nprint(\"Test shape : \",test.shape)","execution_count":4,"outputs":[{"output_type":"stream","text":"Train shape :  (1306122, 3)\nTest shape :  (375806, 2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_vocab(sentences, verbose =  True):\n    \"\"\"\n    :param sentences: list of list of words\n    :return: dictionary of words and their count\n    \"\"\"\n    vocab = {}\n    for sentence in tqdm(sentences, disable = (not verbose)):\n        for word in sentence:\n            try:\n                vocab[word] += 1\n            except KeyError:\n                vocab[word] = 1\n    return vocab","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences = train[\"question_text\"].progress_apply(lambda x: x.split()).values\nvocab = build_vocab(sentences)\nprint({k: vocab[k] for k in list(vocab)[:5]})","execution_count":6,"outputs":[{"output_type":"stream","text":"100%|██████████| 1306122/1306122 [00:09<00:00, 140539.12it/s]\n100%|██████████| 1306122/1306122 [00:08<00:00, 147700.54it/s]","name":"stderr"},{"output_type":"stream","text":"{'How': 261930, 'did': 33489, 'Quebec': 97, 'nationalists': 91, 'see': 9003}\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.models import KeyedVectors\n\nnews_path = '../input/quora-insincere-questions-classification/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\nembeddings_index = KeyedVectors.load_word2vec_format(news_path, binary=True)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import operator \n\ndef check_coverage(vocab,embeddings_index):\n    a = {}\n    oov = {}\n    k = 0\n    i = 0\n    for word in tqdm(vocab):\n        try:\n            a[word] = embeddings_index[word]\n            k += vocab[word]\n        except:\n\n            oov[word] = vocab[word]\n            i += vocab[word]\n            pass\n\n    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n\n    return sorted_x","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oov = check_coverage(vocab,embeddings_index)","execution_count":9,"outputs":[{"output_type":"stream","text":"100%|██████████| 508823/508823 [00:03<00:00, 169539.91it/s]\n","name":"stderr"},{"output_type":"stream","text":"Found embeddings for 24.31% of vocab\nFound embeddings for  78.75% of all text\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"oov[:10]","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"[('to', 403183),\n ('a', 402682),\n ('of', 330825),\n ('and', 251973),\n ('India?', 16384),\n ('it?', 12900),\n ('do?', 8753),\n ('life?', 7753),\n ('you?', 6295),\n ('me?', 6202)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n    if punct in embeddings_index:\n        print(punct)\n    else:\n        print('\\t\\t\\t\\t',punct)","execution_count":11,"outputs":[{"output_type":"stream","text":"\t\t\t\t ?\n\t\t\t\t !\n\t\t\t\t .\n\t\t\t\t ,\n\t\t\t\t \"\n#\n$\n%\n\t\t\t\t '\n\t\t\t\t (\n\t\t\t\t )\n*\n+\n\t\t\t\t -\n\t\t\t\t /\n\t\t\t\t :\n\t\t\t\t ;\n\t\t\t\t <\n=\n>\n@\n\t\t\t\t [\n\t\t\t\t \\\n\t\t\t\t ]\n^\n_\n`\n\t\t\t\t {\n\t\t\t\t |\n\t\t\t\t }\n~\n\t\t\t\t “\n\t\t\t\t ”\n\t\t\t\t ’\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(x):\n    x = str(x)\n    for punct in '&#$%*+=>@^_`~':\n        x = x.replace(punct, f' {punct} ')\n    for punct in '?!.,\"\\'()-/:;<[\\\\]{|}' + '“”’':\n        x = x.replace(punct, '')\n    return x","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"question_text\"] = train[\"question_text\"].progress_apply(lambda x: clean_text(x))\nsentences = train[\"question_text\"].apply(lambda x: x.split())\nvocab = build_vocab(sentences)","execution_count":22,"outputs":[{"output_type":"stream","text":"100%|██████████| 1306122/1306122 [00:21<00:00, 60537.63it/s]\n100%|██████████| 1306122/1306122 [00:08<00:00, 160579.86it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"oov = check_coverage(vocab,embeddings_index)","execution_count":23,"outputs":[{"output_type":"stream","text":"100%|██████████| 279100/279100 [00:01<00:00, 168938.23it/s]\n","name":"stderr"},{"output_type":"stream","text":"Found embeddings for 52.78% of vocab\nFound embeddings for  90.39% of all text\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"oov[:10]","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"[('to', 405812),\n ('a', 404076),\n ('of', 332825),\n ('and', 252936),\n ('doesnt', 6769),\n ('didnt', 3871),\n ('isnt', 2788),\n ('Isnt', 1429),\n ('favourite', 1245),\n ('bitcoin', 972)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(10):\n    print(embeddings_index.index2entity[i])","execution_count":25,"outputs":[{"output_type":"stream","text":"</s>\nin\nfor\nthat\nis\non\n##\nThe\nwith\nsaid\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\ndef clean_numbers(x):\n\n    x = re.sub('[0-9]{5,}', '#####', x)\n    x = re.sub('[0-9]{4}', '####', x)\n    x = re.sub('[0-9]{3}', '###', x)\n    x = re.sub('[0-9]{2}', '##', x)\n    return x","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"question_text\"] = train[\"question_text\"].progress_apply(lambda x: clean_numbers(x))\nsentences = train[\"question_text\"].progress_apply(lambda x: x.split())\nvocab = build_vocab(sentences)","execution_count":27,"outputs":[{"output_type":"stream","text":"100%|██████████| 1306122/1306122 [00:27<00:00, 47517.82it/s]\n100%|██████████| 1306122/1306122 [00:07<00:00, 180178.04it/s]\n100%|██████████| 1306122/1306122 [00:08<00:00, 158443.76it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"oov = check_coverage(vocab,embeddings_index)","execution_count":28,"outputs":[{"output_type":"stream","text":"100%|██████████| 278917/278917 [00:01<00:00, 173804.67it/s]","name":"stderr"},{"output_type":"stream","text":"Found embeddings for 52.83% of vocab\nFound embeddings for  90.39% of all text\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"oov[:20]","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"[('to', 405812),\n ('a', 404076),\n ('of', 332825),\n ('and', 252936),\n ('doesnt', 6769),\n ('didnt', 3871),\n ('isnt', 2788),\n ('Isnt', 1429),\n ('favourite', 1245),\n ('bitcoin', 972),\n ('colour', 971),\n ('Quorans', 877),\n ('centre', 874),\n ('cryptocurrency', 824),\n ('shouldnt', 789),\n ('hasnt', 784),\n ('Snapchat', 779),\n ('wasnt', 743),\n ('travelling', 701),\n ('hisher', 701)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(oov),len(embeddings_index.index2word)","execution_count":71,"outputs":[{"output_type":"execute_result","execution_count":71,"data":{"text/plain":"(131556, 3000000)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count how many word with length from 1 to 10 are there in Google embeddinngs.\ncountfrequencyofword1 = 0\ncountfrequencyofword2 = 0\ncountfrequencyofword3 = 0\ncountfrequencyofword4 = 0\ncountfrequencyofword5 = 0\ncountfrequencyofword6 = 0\ncountfrequencyofword7 = 0\ncountfrequencyofword8 = 0\ncountfrequencyofword9 = 0\ncountfrequencyofword10 = 0\nfor x in embeddings_index.index2word:\n    if len(x) == 1:\n        countfrequencyofword1 += 1\n    if len(x) == 2:\n        countfrequencyofword2 += 1\n    if len(x) == 3:\n        countfrequencyofword3 += 1\n    if len(x) == 4:\n        countfrequencyofword4 += 1\n    if len(x) == 5:\n        countfrequencyofword5 += 1\n    if len(x) == 6:\n        countfrequencyofword6 += 1\n    if len(x) == 7:\n        countfrequencyofword7 += 1\n    if len(x) == 8:\n        countfrequencyofword8 += 1\n    if len(x) == 9:\n        countfrequencyofword9 += 1\n    if len(x) == 10:\n        countfrequencyofword10 += 1\ncountfrequencyofword1,countfrequencyofword2,countfrequencyofword3,countfrequencyofword4,countfrequencyofword5,countfrequencyofword6,countfrequencyofword7,countfrequencyofword8,countfrequencyofword9,countfrequencyofword10","execution_count":74,"outputs":[{"output_type":"execute_result","execution_count":74,"data":{"text/plain":"(760, 3659, 28786, 81317, 112528, 156565, 179773, 173561, 165129, 165799)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"760+ 3659+ 28786+ 81317+ 112528+ 156565+ 179773+ 173561+ 165129+ 165799\n# the total amount of words of which length vary from 1 to 10 is just 1067877, which means\n# there're still nearly 2 million words of which length are greater than 10.","execution_count":75,"outputs":[{"output_type":"execute_result","execution_count":75,"data":{"text/plain":"1067877"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"havent\" in embeddings_index","execution_count":91,"outputs":[{"output_type":"execute_result","execution_count":91,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in oov:\n    if \"Havent\" in x[0]:\n        print('yes')","execution_count":92,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n    return mispell_dict, mispell_re\n\n\nmispell_dict = {'colour':'color',\n                'centre':'center',\n                'didnt':'didn\\'t',\n                'doesnt':'doesn\\'t',\n                'Doesnt':'doesn\\'t',\n                'isnt':'isn\\'t',\n                'Isnt':'isn\\'t',\n                'arent':'aren\\'t',\n                'werent':'weren\\'t',\n                'Werent':'weren\\'t',\n                'havent':'haven\\'t',\n                'shouldnt':'shouldn\\'t',\n                'Shouldnt':'shouldn\\'t',\n                'couldnt':'couldn\\'t',\n                'favourite':'favorite',\n                'travelling':'traveling',\n                'counselling':'counseling',\n                'theatre':'theater',\n                'cancelled':'canceled',\n                'labour':'labor',\n                'organisation':'organization',\n                'wwii':'world war 2',\n                'citicise':'criticize',\n                'instagram':'Instagram',\n                'whatsapp':'social medium',\n                'snapchat':'social medium',\n                'wechat':'social medium'\n\n                }\nmispellings, mispellings_re = _get_mispell(mispell_dict)\n\ndef replace_typical_misspell(text):\n    def replace(match):\n        return mispellings[match.group(0)]\n\n    return mispellings_re.sub(replace, text)","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def missingOne(s1, s2):\n    if len(s1)+1 != len(s2):\n        return False\n    cnt = 0\n    for i in range(0,len(s1)):\n        if cnt == 0:\n            if s1[i] == s2[i]:\n                print('1 cnt: ',cnt,' s1[',i,']: ',s1[i],' s2[',i,']: ',s2[i])\n                pass\n            elif s1[i] == s2[i+1]:\n                print('2 cnt: ',cnt,' s1[',i,']: ',s1[i],' s2[',i+1,']: ',s2[i+1])\n                cnt += 1\n                pass\n            else:\n                return False\n        elif cnt == 1:\n            if s1[i] == s2[i+1]:\n                print('3 cnt: ',cnt,' s1[',i,']: ',s1[i],' s2[',i+1,']: ',s2[i+1])\n                pass\n            else:\n                return False\n        else:\n            return False\n    return True","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}